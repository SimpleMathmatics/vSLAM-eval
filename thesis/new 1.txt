related work statt methods 
kapitel mit: punktwolken, 
setup in results
3 evaluation
4 discussion

	Furthemore, a framework to test and build an entire automated system is suggested. This framework includes a simulated 
	simulated envorinment, that realisicly makes it possible, to navigate a drone within an simulated environment. The environment 
	is based on the Roboter Operating System (ROS) and for the simulations the tum_simulation ros package was resorted to. 
	Thus, 
	you can navigate an AR.drone 1.0 and 2.0 in different worlds created with a gazebo node. This drone is eqipped with a bottom camera 
	and a frot camera. The cameras each log their output to a ros topic. Additionally, message time stamps, the height sensor output, 
	battery percentage, position, rotation
	velocity and accelaration are also logged to rostopics. While the drone can also be navigated using a playstation 3 controller, 
	for an automated system, the drone should rather be addressed using the command line interface. For example 
	the command shown in sourcecode listing \ref{lst:drone_cmd} will make the drone fly foreward. 
	
	\begin{lstlisting}[language=bash, caption=drone navigation command, label=lst:drone_cmd]
    rostopic pub -r 10 /cmd_vel geometry_msgs/Twist  '{linear:  {x: 1.0, y: 0.0, z: 0.0}, angular: {x: 0.0,y: 0.0,z: 0.0}}'
	\end{lstlisting}
	
	\fig{img/tum_sim.png}{tum_sim setup. Source: http://wiki.ros.org/tum_simulator}{fig:tum_sim}{0.8}
	
	By accessing the camera output of the drone via rostopics, SLAM algorithms can be applied on the generated images. Some SLAM-Algorithms, 
	such as an modified version of the ORB-SLAM-Algorithm (\href{<url>}{<ORB_SLAM2_ROS>}), publish the created pointcloud again in an own rostopic. 
	
	
	% theconstr


	\begin{figure}%
    \centering
    \subfloat[\centering gazebo simulation]{{\includegraphics[width=5cm]{img/drohne_oben.png} }}%
    \qquad
    \subfloat[\centering front camera simulation]{{\includegraphics[width=5cm]{img/drohne_kamera.png} }}%
	\qquad
    \subfloat[\centering ORB applied on simulation]{{\includegraphics[width=5cm]{img/front_camera_orb.png} }}%
    \caption{
	The drone in a gazebo simulation in a), the output of the front camera of the drone in b) and
	the ORB-SLAM algorithm applied on the front camera output in with the detected ORB features marked green c).
	}%
    \label{fig:sim_figs}%
	\end{figure}
	
	
	
% hier auch noch CNN slam erw√§hnen
% nur default parameters used...mit extra vocab und grid search noch ausbesserbar. 


	\begin{figure}%
    \centering
    \subfloat[\centering trajectory error]{{\includegraphics[width=6cm]{img/down_error.png} }}%
	\qquad
    \subfloat[\centering computation time]{{\includegraphics[width=6cm]{img/down_comp.png} }}%
    \caption{
	Influence of downsizing of the images on the trajectory error (a) and the computation time (b) for the sequence V101. 
	}%
    \label{fig:resolution}%
	\end{figure}